version: '3.8'

services:
  diffusion-pipe:
    build: .
    image: diffusion-pipe:latest
    container_name: diffusion-pipe-dev
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - NCCL_P2P_DISABLE=1
      - NCCL_IB_DISABLE=1
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    volumes:
      # Mount the project directory for development
      - .:/workspace
      # Mount datasets directory (adjust path as needed)
      - ./datasets:/workspace/datasets
      # Mount outputs directory to persist training results
      - ./outputs:/workspace/outputs
      # Optional: Mount model cache directory to avoid re-downloading
      - ~/.cache/huggingface:/root/.cache/huggingface
    working_dir: /workspace
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Default command to keep container running
    command: ["conda", "run", "-n", "diffusion-pipe", "bash", "-c", "tail -f /dev/null"]

  # Optional: Tensorboard service for monitoring training
  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: diffusion-pipe-tensorboard
    ports:
      - "6006:6006"
    volumes:
      - ./outputs:/logs
    command: ["tensorboard", "--logdir=/logs", "--host=0.0.0.0", "--port=6006"]
    profiles:
      - tensorboard